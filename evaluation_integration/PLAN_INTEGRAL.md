# Plan Integral: Sistema de Correcci√≥n Autom√°tica de Ex√°menes

**Fecha**: 21 de Octubre, 2025
**Objetivo**: Implementar sistema completo de correcci√≥n de ex√°menes usando Claude Haiku
**Estado**: üìã Planificaci√≥n

---

## üéØ Objetivo del Sistema

Permitir la correcci√≥n autom√°tica de ex√°menes transcritos en archivos `.md`, donde:
- El **apellido del alumno** est√° en el nombre del archivo (ej: `Gonzalez.md`, `Di_Bernardo.md`)
- El **contenido** es la transcripci√≥n del examen (puede ser de cualquier tema)
- La **correcci√≥n** usa una r√∫brica gen√©rica adaptable
- El **resultado** se guarda en la tabla `Evaluation` con feedback detallado

---

## üìä An√°lisis del Estado Actual

### ‚úÖ Infraestructura Existente

#### 1. Base de Datos (Turso libSQL)

**Tabla `Evaluation`** - Estructura perfecta:
```sql
- id (TEXT, PRIMARY KEY)
- studentId (TEXT, NOT NULL)         ‚Üê Buscar por apellido
- subject (TEXT, NOT NULL)            ‚Üê Asignatura del examen
- examDate (TEXT, NOT NULL)           ‚Üê Fecha del examen
- examTopic (TEXT, NOT NULL)          ‚Üê Tema espec√≠fico
- score (INTEGER, NOT NULL)           ‚Üê Nota 0-100
- feedback (TEXT, NOT NULL)           ‚Üê Feedback en Markdown
- createdBy (TEXT, NOT NULL)          ‚Üê ID del instructor
- createdAt (TEXT, DEFAULT now())
- updatedAt (TEXT, DEFAULT now())
```

**Tabla `User`** - Para buscar estudiantes:
```sql
- id (TEXT, PRIMARY KEY)
- name (TEXT)                         ‚Üê Formato: "Apellido, Nombre"
- role (TEXT)                         ‚Üê STUDENT
- status (TEXT)                       ‚Üê ACTIVE
- academicYear (TEXT)                 ‚Üê "4to A√±o", "5to A√±o"
- division (TEXT)                     ‚Üê "A", "B", "C"
- subjects (TEXT)                     ‚Üê "F√≠sica, Qu√≠mica"
```

#### 2. Sistema AI Existente

**Claude Haiku 4.5 Integrado** (`src/services/ai/claude/`):
- ‚úÖ Cliente configurado con lazy initialization
- ‚úÖ Prompt Caching (ahorro 70-90%)
- ‚úÖ Sistema de r√∫bricas por fases (1-4)
- ‚úÖ Evaluaci√≥n por preguntas con niveles 1-4
- ‚úÖ C√°lculo de m√©tricas de habilidades
- ‚úÖ Analyzer con formato estructurado

**Formato de Feedback Existente** (ejemplo real):
```markdown
# RETROALIMENTACI√ìN - [NOMBRE ESTUDIANTE]
## Examen: [Materia] - [Tema]
### Fecha: [Fecha]
### Nota: [Score]/100

---

## üìä Tu Progreso Hist√≥rico
[M√©tricas de semanas anteriores si existen]

## üîç An√°lisis de tu Examen
### Ejercicio 1: [T√≠tulo]
- Lo que esper√°bamos de ti
- Lo que demostraste
- Comparaci√≥n vs expectativa
- Retroalimentaci√≥n espec√≠fica

### Ejercicio 2: [T√≠tulo]
[Mismo formato]

## üéØ Validaci√≥n de tu Progreso
[Predicciones vs realidad]

## üí° Recomendaciones Personalizadas
[3-4 recomendaciones espec√≠ficas]

## üìà Pr√≥ximos Pasos
[Plan de mejora]

## üìå Mensaje Final
[Motivaci√≥n personalizada]
```

#### 3. Sistema de R√∫bricas

**Actual** (Reportes Semanales):
- 4 Fases metodol√≥gicas (Identificaci√≥n ‚Üí Evaluaci√≥n ‚Üí Planificaci√≥n ‚Üí Implementaci√≥n)
- 5 Preguntas (Q1-Q5) con ponderaciones (25%, 25%, 20%, 20%, 10%)
- 4 Niveles de desempe√±o (1-4) con descriptores detallados
- 5 M√©tricas de habilidades transversales

**Necesidad para Ex√°menes**:
- ‚ö†Ô∏è R√∫brica gen√©rica (no espec√≠fica de fase)
- ‚ö†Ô∏è Adaptable a cualquier tema/asignatura
- ‚ö†Ô∏è Enfocada en resoluci√≥n de problemas/ejercicios
- ‚úÖ Mantener m√©tricas de habilidades
- ‚úÖ Mantener niveles 1-4

---

## üèóÔ∏è Arquitectura Propuesta

### Componente 1: R√∫brica Gen√©rica de Ex√°menes

**Estructura**: 5 Dimensiones de Evaluaci√≥n

```typescript
// Dimensiones de evaluaci√≥n (reemplaza Q1-Q5)
export const DIMENSIONES_EXAMEN = {
  D1_COMPRENSION: 0.25,      // 25% - Comprensi√≥n del problema
  D2_METODOLOGIA: 0.25,      // 25% - Metodolog√≠a y estrategia
  D3_EJECUCION: 0.25,        // 25% - Ejecuci√≥n y c√°lculos
  D4_JUSTIFICACION: 0.15,    // 15% - Justificaci√≥n y razonamiento
  D5_VERIFICACION: 0.10      // 10% - Verificaci√≥n y an√°lisis cr√≠tico
} as const;
```

**Niveles de Desempe√±o** (mantener sistema actual):
- Nivel 4 (85-100): Excelente ‚Üí 92.5 puntos
- Nivel 3 (70-84): Bueno ‚Üí 77 puntos
- Nivel 2 (55-69): En desarrollo ‚Üí 62 puntos
- Nivel 1 (0-54): Inicial ‚Üí 27 puntos

### Componente 2: Parser de Archivos

**Input**: Archivo `.md` con nombre `[Apellido].md`

**Proceso**:
1. Extraer apellido del nombre de archivo
2. Buscar estudiante en DB por coincidencia de apellido
3. Leer contenido completo del archivo
4. Identificar estructura del examen (ejercicios, respuestas)

**Output**:
```typescript
interface ParsedExam {
  studentInfo: {
    id: string;
    name: string;
    apellido: string;
    academicYear: string;
    division: string;
  };
  examContent: {
    rawText: string;
    exercises: Exercise[];
  };
  metadata: {
    fileName: string;
    fileSize: number;
    parseDate: Date;
  };
}

interface Exercise {
  number: number;
  title?: string;
  content: string;
  hasAnswer: boolean;
}
```

### Componente 3: Corrector AI (Claude Haiku)

**Input**: `ParsedExam` + metadatos del examen

**Proceso** (usando prompt caching):
```typescript
interface CorrectionRequest {
  parsedExam: ParsedExam;
  examMetadata: {
    subject: string;       // "F√≠sica", "Qu√≠mica", etc.
    topic: string;         // "Tiro Oblicuo", "Termodin√°mica", etc.
    examDate: string;      // "2025-10-15"
    maxScore: number;      // 100 (default)
  };
  instructorId: string;
  options?: {
    includeHistoricalComparison: boolean;  // Comparar con reportes previos
    detailLevel: 'basic' | 'detailed';    // Nivel de detalle
  };
}
```

**System Prompt** (cacheable):
```
Eres un asistente experto en correcci√≥n de ex√°menes de [MATERIA].

Tu tarea es evaluar ex√°menes usando una r√∫brica gen√©rica de 5 dimensiones:

1. COMPRENSI√ìN (25%): Entendimiento del problema
2. METODOLOG√çA (25%): Selecci√≥n de estrategia
3. EJECUCI√ìN (25%): Desarrollo y c√°lculos
4. JUSTIFICACI√ìN (15%): Razonamiento l√≥gico
5. VERIFICACI√ìN (10%): An√°lisis cr√≠tico

Para cada dimensi√≥n, asigna un nivel 1-4:
- Nivel 4 (85-100): Excelente
- Nivel 3 (70-84): Bueno
- Nivel 2 (55-69): En desarrollo
- Nivel 1 (0-54): Inicial

[R√öBRICA GEN√âRICA COMPLETA - CACHEABLE]
```

**User Prompt** (NO cacheable):
```
Estudiante: [Nombre]
Examen: [Materia] - [Tema]
Fecha: [Fecha]

[TRANSCRIPCI√ìN DEL EXAMEN]

Eval√∫a ejercicio por ejercicio usando la r√∫brica.
```

**Output**: Estructura JSON
```typescript
interface AIAnalysis {
  scores: {
    D1_COMPRENSION: { nivel: 1 | 2 | 3 | 4; puntaje: number; };
    D2_METODOLOGIA: { nivel: 1 | 2 | 3 | 4; puntaje: number; };
    D3_EJECUCION: { nivel: 1 | 2 | 3 | 4; puntaje: number; };
    D4_JUSTIFICACION: { nivel: 1 | 2 | 3 | 4; puntaje: number; };
    D5_VERIFICACION: { nivel: 1 | 2 | 3 | 4; puntaje: number; };
  };
  totalScore: number;  // 0-100 (promedio ponderado)
  exerciseAnalysis: ExerciseAnalysis[];
  generalFeedback: string;
  recommendations: string[];
}

interface ExerciseAnalysis {
  exerciseNumber: number;
  strengths: string[];
  weaknesses: string[];
  specificFeedback: string;
}
```

### Componente 4: Enriquecedor de Feedback

**Funci√≥n**: Agregar contexto hist√≥rico del estudiante

**Proceso**:
1. Buscar reportes semanales previos del estudiante en `Feedback`
2. Buscar evaluaciones previas del estudiante en `Evaluation`
3. Calcular tendencias y comparar con desempe√±o actual
4. Generar predicciones vs realidad (como en feedbacks actuales)

**Output**: Feedback enriquecido en formato Markdown

### Componente 5: Gestor de Base de Datos

**Funci√≥n**: Guardar resultado en tabla `Evaluation`

```typescript
interface EvaluationRecord {
  id: string;               // "eval_[hash]"
  studentId: string;        // Del parsing
  subject: string;          // Del metadata
  examDate: string;         // Del metadata
  examTopic: string;        // Del metadata
  score: number;            // Del AI analysis
  feedback: string;         // Markdown enriquecido
  createdBy: string;        // Instructor ID
  createdAt: string;        // now()
  updatedAt: string;        // now()
}
```

### Componente 6: UI para Instructores

**P√°ginas**:
1. **Upload de Ex√°menes** (`/dashboard/instructor/exams/upload`)
   - Drag & drop de archivos `.md`
   - Selector de materia
   - Input de tema del examen
   - Date picker para fecha del examen
   - Preview de archivos antes de procesar

2. **Configuraci√≥n de Correcci√≥n** (mismo formulario)
   - Selecci√≥n de r√∫brica (futura: personalizada vs gen√©rica)
   - Toggle: incluir an√°lisis hist√≥rico
   - Nivel de detalle (b√°sico vs detallado)

3. **Vista de Progreso** (durante correcci√≥n)
   - Lista de archivos con status (pending, processing, completed, error)
   - Progress bar global
   - Logs en tiempo real

4. **Resultados** (`/dashboard/instructor/exams/results`)
   - Tabla de ex√°menes corregidos
   - Preview de feedback
   - Exportar a PDF
   - Re-procesar si hay error

---

## üîÑ Workflow Completo

### Fase 1: Upload & Parsing

```
Usuario ‚Üí Upload .md files
    ‚Üì
Parser extrae apellido del filename
    ‚Üì
Buscar estudiante en User table
    ‚Üì
[MATCH FOUND] ‚Üí ParsedExam
    ‚Üì
[NO MATCH] ‚Üí Error: "No se encontr√≥ estudiante con apellido X"
```

### Fase 2: Correcci√≥n AI

```
ParsedExam + Metadata
    ‚Üì
Build cacheable system prompt (r√∫brica gen√©rica)
    ‚Üì
Build user prompt (transcripci√≥n)
    ‚Üì
Claude Haiku API call
    ‚Üì
Parse JSON response
    ‚Üì
Calculate weighted scores
    ‚Üì
AIAnalysis object
```

### Fase 3: Enriquecimiento

```
AIAnalysis + studentId
    ‚Üì
Query Feedback table (√∫ltimos 5 reportes)
    ‚Üì
Query Evaluation table (√∫ltimos 3 ex√°menes)
    ‚Üì
Calculate historical trends
    ‚Üì
Generate comparative analysis
    ‚Üì
Build enriched Markdown feedback
```

### Fase 4: Persistencia

```
Enriched Feedback + Metadata
    ‚Üì
Generate evaluation ID
    ‚Üì
Insert into Evaluation table
    ‚Üì
Return evaluation record
```

---

## üìÅ Estructura de Archivos Propuesta

```
evaluation_integration/
‚îú‚îÄ‚îÄ PLAN_INTEGRAL.md              ‚Üê Este archivo
‚îú‚îÄ‚îÄ RUBRICA_GENERICA.md            ‚Üê R√∫brica detallada para ex√°menes
‚îú‚îÄ‚îÄ ARCHITECTURE.md                ‚Üê Diagrams y decisiones t√©cnicas
‚îú‚îÄ‚îÄ API_SPEC.md                    ‚Üê Especificaci√≥n de API endpoints
‚îú‚îÄ‚îÄ EJEMPLOS/
‚îÇ   ‚îú‚îÄ‚îÄ examen_input_ejemplo.md   ‚Üê Ejemplo de archivo de entrada
‚îÇ   ‚îú‚îÄ‚îÄ parsed_exam_ejemplo.json  ‚Üê Output del parser
‚îÇ   ‚îú‚îÄ‚îÄ ai_analysis_ejemplo.json  ‚Üê Output de Claude
‚îÇ   ‚îî‚îÄ‚îÄ feedback_final_ejemplo.md ‚Üê Feedback enriquecido
‚îî‚îÄ‚îÄ TESTING/
    ‚îú‚îÄ‚îÄ test_cases.md             ‚Üê Casos de prueba
    ‚îî‚îÄ‚îÄ validation_criteria.md    ‚Üê Criterios de validaci√≥n
```

---

## üõ†Ô∏è Implementaci√≥n por Fases

### Fase 1: Fundamentos (Semana 1)
**Objetivo**: R√∫brica + Parser funcionando

**Tasks**:
- [ ] Dise√±ar r√∫brica gen√©rica completa (5 dimensiones √ó 4 niveles)
- [ ] Implementar parser de archivos `.md`
- [ ] L√≥gica de b√∫squeda de estudiantes por apellido
- [ ] Unit tests del parser
- [ ] Documentar casos edge (apellidos compuestos, tildes, etc.)

**Entregables**:
- `evaluation_integration/RUBRICA_GENERICA.md`
- `src/lib/exam-parser.ts`
- `src/lib/student-matcher.ts`
- Tests: `__tests__/exam-parser.test.ts`

---

### Fase 2: Correcci√≥n AI (Semana 2)
**Objetivo**: Integraci√≥n con Claude Haiku

**Tasks**:
- [ ] Adaptar `EducationalAnalyzer` para ex√°menes
- [ ] Crear `ExamAnalyzer` class
- [ ] Implementar prompt caching con r√∫brica gen√©rica
- [ ] Parser de respuesta JSON de Claude
- [ ] C√°lculo de scores ponderados
- [ ] Testing con ex√°menes reales

**Entregables**:
- `src/services/ai/exam/analyzer.ts`
- `src/services/ai/exam/prompts/rubrica-generica.ts`
- Tests con mock de Claude API

---

### Fase 3: Enriquecimiento (Semana 2-3)
**Objetivo**: Feedback contextualizado

**Tasks**:
- [ ] Query de datos hist√≥ricos (Feedback + Evaluation)
- [ ] C√°lculo de tendencias y promedios
- [ ] Comparaci√≥n predicci√≥n vs realidad
- [ ] Template de Markdown enriquecido
- [ ] Integraci√≥n con formato actual

**Entregables**:
- `src/lib/feedback-enricher.ts`
- `src/lib/templates/exam-feedback.ts`
- Tests de enriquecimiento

---

### Fase 4: Persistencia (Semana 3)
**Objetivo**: Guardar en BD

**Tasks**:
- [ ] DB operations para Evaluation table
- [ ] Generaci√≥n de IDs √∫nicos
- [ ] Transaction handling
- [ ] Error recovery
- [ ] Logging completo

**Entregables**:
- `src/lib/db-operations-exam.ts`
- Tests de DB operations

---

### Fase 5: API Backend (Semana 3-4)
**Objetivo**: Endpoints para UI

**Tasks**:
- [ ] POST `/api/instructor/exams/upload` - Upload files
- [ ] POST `/api/instructor/exams/correct` - Start correction
- [ ] GET `/api/instructor/exams/status/:batchId` - Check progress
- [ ] GET `/api/instructor/exams/results/:evaluationId` - Get feedback
- [ ] Authentication & authorization
- [ ] Rate limiting

**Entregables**:
- `src/app/api/instructor/exams/upload/route.ts`
- `src/app/api/instructor/exams/correct/route.ts`
- `src/app/api/instructor/exams/status/[batchId]/route.ts`
- `src/app/api/instructor/exams/results/[evaluationId]/route.ts`

---

### Fase 6: UI Frontend (Semana 4-5)
**Objetivo**: Interface completa para instructores

**Tasks**:
- [ ] P√°gina de upload con drag & drop
- [ ] Formulario de configuraci√≥n
- [ ] Vista de progreso en tiempo real
- [ ] Tabla de resultados
- [ ] Preview de feedback
- [ ] Export a PDF

**Entregables**:
- `src/app/dashboard/instructor/exams/page.tsx`
- `src/components/instructor/ExamUploader.tsx`
- `src/components/instructor/ExamResults.tsx`
- `src/components/instructor/FeedbackPreview.tsx`

---

### Fase 7: Testing & Refinamiento (Semana 5-6)
**Objetivo**: Sistema production-ready

**Tasks**:
- [ ] Testing end-to-end con ex√°menes reales
- [ ] Validaci√≥n con instructores
- [ ] Ajustes de r√∫brica basados en feedback
- [ ] Performance optimization
- [ ] Error handling completo
- [ ] Documentation completa

**Entregables**:
- Test suite completo
- Documentaci√≥n de usuario
- Gu√≠a de troubleshooting

---

## üí∞ Estimaci√≥n de Costos

### Costo por Examen

**Asumiendo**:
- 1 examen = 2-3 ejercicios
- Transcripci√≥n promedio: 1,000 tokens
- R√∫brica gen√©rica (cacheable): 5,000 tokens
- Response esperado: 1,500 tokens

**Con Prompt Caching**:
```
Input (primera correcci√≥n):  6,000 tokens √ó $0.30/MTok = $0.0018
Output:                       1,500 tokens √ó $1.50/MTok = $0.00225
TOTAL PRIMERA:                                            $0.00405

Input (siguientes, cache hit): 1,000 tokens √ó $0.30/MTok = $0.0003
Output:                        1,500 tokens √ó $1.50/MTok = $0.00225
TOTAL CON CACHE:                                          $0.00255
```

**Batch de 30 ex√°menes**:
```
Primer examen:     $0.00405
29 ex√°menes:       29 √ó $0.00255 = $0.07395
TOTAL BATCH:                       $0.07800 ‚âà $0.08

Costo unitario promedio: $0.0026 por examen
```

### Proyecci√≥n Mensual

**Escenario conservador**:
- 4 cursos √ó 30 alumnos = 120 ex√°menes/mes
- Costo: 120 √ó $0.0026 = **$0.31/mes**

**Escenario alto**:
- 8 cursos √ó 30 alumnos √ó 2 ex√°menes/mes = 480 ex√°menes/mes
- Costo: 480 √ó $0.0026 = **$1.25/mes**

**Muy por debajo del presupuesto de $10/mes** ‚úÖ

---

## üéØ Criterios de √âxito

### M√©tricas T√©cnicas

- **Accuracy de matching**: >95% de apellidos correctamente identificados
- **Parse success rate**: >98% de archivos parseados sin error
- **AI consistency**: Score variance <5 puntos en re-correcciones
- **Processing time**: <30s por examen (incluyendo enrichment)
- **API response time**: <3s para upload, <5s para status check

### M√©tricas de Calidad

- **Feedback relevance**: >90% de instructores aprueban el feedback
- **Error detection**: Sistema detecta >80% de errores conceptuales
- **Recommendation quality**: >75% de recomendaciones consideradas √∫tiles
- **Student understanding**: >70% de estudiantes entienden el feedback

### M√©tricas de Negocio

- **Adoption rate**: >50% de instructores usan el sistema
- **Time saved**: Reducci√≥n de 80% en tiempo de correcci√≥n manual
- **Cost effectiveness**: <$0.01 por examen corregido
- **Scalability**: Soporta hasta 500 ex√°menes/mes sin degradaci√≥n

---

## üö® Riesgos y Mitigaciones

### Riesgo 1: Apellidos Mal Identificados

**Probabilidad**: Media
**Impacto**: Alto (correcci√≥n asignada al estudiante equivocado)

**Mitigaci√≥n**:
- Algoritmo fuzzy matching con threshold de 90%
- Lista de apellidos ambiguos (manual override)
- Preview UI antes de procesar
- Confirmaci√≥n del instructor obligatoria

### Riesgo 2: Transcripciones Ambiguas

**Probabilidad**: Alta
**Impacto**: Medio (feedback de menor calidad)

**Mitigaci√≥n**:
- Guidelines claras para transcripci√≥n
- Template de transcripci√≥n sugerido
- Parser robusto que tolera variaciones
- Feedback a instructor si parse es ambiguo

### Riesgo 3: R√∫brica Gen√©rica Poco Espec√≠fica

**Probabilidad**: Media
**Impacto**: Medio (feedback menos preciso)

**Mitigaci√≥n**:
- Iteraci√≥n continua de la r√∫brica basada en feedback
- Opci√≥n futura de r√∫bricas espec√≠ficas por materia
- Validaci√≥n con instructores expertos
- A/B testing de diferentes versiones

### Riesgo 4: Costos Inesperadamente Altos

**Probabilidad**: Baja
**Impacto**: Medio

**Mitigaci√≥n**:
- Prompt caching agresivo (r√∫brica, contexto hist√≥rico)
- Monitoreo continuo de costos
- Alertas si costo >$0.01 por examen
- Optimizaci√≥n de prompts si es necesario

---

## üìö Casos de Uso

### Caso 1: Examen de F√≠sica - Tiro Oblicuo

**Input**: `Gonzalez.md`
```markdown
# Examen de F√≠sica - Tiro Oblicuo

**Alumno**: Gonz√°lez

## Ejercicio 1
Una pelota es lanzada con velocidad inicial de 20 m/s y √°ngulo de 30¬∞.
Calcular alcance m√°ximo.

**Desarrollo**:
Vox = 20 * cos(30¬∞) = 17.32 m/s
Voy = 20 * sen(30¬∞) = 10 m/s
t = 2 * Voy / g = 2 * 10 / 10 = 2s
Alcance = Vox * t = 17.32 * 2 = 34.64 m

## Ejercicio 2
[...]
```

**Output**: Feedback detallado con:
- An√°lisis de cada ejercicio
- Scores en 5 dimensiones
- Nota final: 85/100
- Comparaci√≥n con reportes semanales previos
- Recomendaciones personalizadas

### Caso 2: Examen de Qu√≠mica - Estequiometr√≠a

**Input**: `DiBernardo.md` (apellido compuesto)
```markdown
# Examen de Qu√≠mica

**Alumno**: Di Bernardo

## Ejercicio 1
Balancear: H2 + O2 ‚Üí H2O

**Respuesta**:
2 H2 + O2 ‚Üí 2 H2O

[...]
```

**Output**: Sistema reconoce apellido compuesto, busca match en DB, genera feedback adaptado a qu√≠mica

---

## üîÑ Integraciones Futuras

### Fase 8 (Futura): Mejoras Avanzadas

1. **OCR Integration**
   - Permitir upload de PDFs/im√°genes de ex√°menes escritos a mano
   - OCR autom√°tico ‚Üí transcripci√≥n ‚Üí correcci√≥n

2. **R√∫bricas Personalizadas**
   - Instructores crean sus propias r√∫bricas
   - Sistema aprende de correcciones manuales
   - Ajuste autom√°tico de pesos

3. **An√°lisis Predictivo**
   - Predicci√≥n de rendimiento en pr√≥ximo examen
   - Identificaci√≥n temprana de estudiantes en riesgo
   - Recomendaciones de intervenci√≥n

4. **Dashboard de M√©tricas**
   - An√°lisis de tendencias por curso
   - Comparaci√≥n entre divisiones
   - Identificaci√≥n de temas dif√≠ciles

5. **Export & Sharing**
   - Export a PDF con formato profesional
   - Compartir feedback directamente con estudiantes
   - Notificaciones autom√°ticas

---

## üìû Pr√≥ximos Pasos Inmediatos

### Esta Semana:

1. **Revisar y aprobar este plan** ‚úÖ
2. **Crear r√∫brica gen√©rica detallada** (RUBRICA_GENERICA.md)
3. **Dise√±ar arquitectura t√©cnica** (ARCHITECTURE.md)
4. **Preparar ejemplos de entrada/salida** (carpeta EJEMPLOS/)

### Pr√≥xima Semana:

1. Implementar parser de archivos
2. Implementar matcher de apellidos
3. Testing inicial con archivos de ejemplo
4. Ajustes basados en resultados

---

**Estado**: üìã Plan aprobado pendiente
**Pr√≥xima revisi√≥n**: Despu√©s de Fase 1 (parser implementado)
**Owner**: Rodrigo Di Bernardo
**AI Assistant**: Claude Code (Sonnet 4.5)
